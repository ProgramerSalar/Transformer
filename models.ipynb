{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model:int, vocab_size:int ) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model   # d_model which represents the dimension of the model (i.e., the size of the word embeddings).\n",
    "        self.vocab_size = vocab_size  # vocab_size which represents the size of the vocabulary. For instance, the GPT-3 model by OpenAI has a vocabulary size of approximately 14,735,746 words\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)  # size of the word and vocab size, do the embedding \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model) # The embeddings are scaled by multiplying with the square root of d_model as recommended in the \"Attention is All You Need\" paper.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece of code defines a class named InputEmbeddings that inherits from nn.Module. nn.Module is the base class for all neural network modules in PyTorch, a popular deep learning library. This class, InputEmbeddings, represents an embedding layer in a neural network model.\n",
    "\n",
    "Explanation of the Code\n",
    "\n",
    "Let's break down the methods present in the class:\n",
    "\n",
    "__init__(self, d_model:int, vocab_size:int ) -> None:\n",
    "\n",
    "This is the constructor method for the class which initializes the instance. It takes three arguments:\n",
    "\n",
    "self which represents the instance of the class.\n",
    "d_model which represents the dimension of the model (i.e., the size of the word embeddings).\n",
    "vocab_size which represents the size of the vocabulary.\n",
    "\n",
    "In the body of the constructor, it calls the constructor of the parent class (nn.Module) with super().__init__(), stores the provided d_model and vocab_size into instance variables, and then initializes an embedding layer using PyTorch's nn.Embedding. nn.Embedding is a simple lookup table that stores embeddings of a fixed dictionary and size. The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
    "\n",
    "forward(self, x):\n",
    "\n",
    "This method defines the forward pass of the embedding layer. In other words, it describes how the module processes input data (x). It returns the input data passed through the embedding layer and scales the embedding according to the paper's recommendation by multiplying it by the square root of d_model. The scaling is a trick the authors of the \"Attention is All You Need\" paper use to get the model to learn better.\n",
    "\n",
    "Key Points\n",
    "\n",
    "InputEmbeddings is a class that defines an embedding layer in a neural network.\n",
    "It inherits from the nn.Module class, the base class for all neural network modules in PyTorch.\n",
    "The nn.Embedding layer is a simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "The forward method defines how the module processes input data.\n",
    "The embeddings are scaled by multiplying with the square root of d_model as recommended in the \"Attention is All You Need\" paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
